{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bc4d60-4174-4a55-8886-f9cea1d8a8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:52:02.535474Z",
     "start_time": "2025-06-04T17:52:02.530253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 16:05:40.739407: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-05 16:05:40.752901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749132340.767794  816694 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749132340.772393  816694 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-05 16:05:40.788872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful!!\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "# Import classifier\n",
    "#from ipynb.fs.full.group_classifier import predict_batch\n",
    "from group_classifier import predict_batch\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "# Disables progress bar of .map function\n",
    "disable_progress_bar()\n",
    "print(\"Import successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9c2acf-64d4-4cf4-a816-c9315fef11f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:52:03.428873Z",
     "start_time": "2025-06-04T17:52:03.417474Z"
    }
   },
   "outputs": [],
   "source": [
    " # Connect to sql database\n",
    "con = duckdb.connect(database='../data/database/german-parliament.duckdb', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a49673-3f68-4987-a75c-4ec16e6ed945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:14:43.294435Z",
     "start_time": "2025-06-04T18:14:43.291083Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_speech(speech: tuple) -> tuple[int, list[dict[str, str]]]:\n",
    "    \"\"\"The filtering for skipping_president_remarks is only necessare for periods >= 19 because of the \"new\" format provided by the bundestag. \n",
    "    For periods <19 the method just extracs all the 'p' tags\n",
    "    \"\"\"\n",
    "    speech_id = speech[0]\n",
    "    text_content = speech[5]\n",
    "\n",
    "    # Parse xml from string will throw ParseError if not parseable\n",
    "    root = ET.fromstring(text_content)\n",
    "    \n",
    "    paragraphs_text = []\n",
    "    # skipping_president_remarks is used to detect interruptions of the President\n",
    "    skipping_president_remarks = False\n",
    "\n",
    "    # Iterate over all direct children of the root <rede> element\n",
    "    for element in root:\n",
    "        # 1. Check if we need to STOP skipping\n",
    "        if skipping_president_remarks:\n",
    "            if element.tag == 'p' and element.attrib.get(\"klasse\") == \"redner\":\n",
    "                # We know that the interruption of the president ended and the speech continues after this tag\n",
    "                skipping_president_remarks = False\n",
    "                continue \n",
    "            elif element.tag == 'p':\n",
    "                # Do nothing -> president is speaking\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Detected unexpected tag: {element.tag}\")\n",
    "\n",
    "        # 2. Check if we need to START skipping (President speaks)\n",
    "        if element.tag == 'name':\n",
    "            # Check if the text content of the name tag indicates a presiding\n",
    "            name_text = \"\".join(element.itertext()).strip() # Gets all text within <name>, including children\n",
    "            # State all titles which will get ignored\n",
    "            president_titles = [\"Präsidentin\", \"Präsident\", \"Vizepräsidentin\", \"Vizepräsident\"]\n",
    "            if name_text and any(title in name_text for title in president_titles):\n",
    "                skipping_president_remarks = True\n",
    "                continue # Move to the next element, don't process this <name> tag as a paragraph\n",
    "\n",
    "        # 3. Process <p> tags\n",
    "        if element.tag == 'p':\n",
    "            # Filter out speaker information paragraphs\n",
    "            if element.attrib.get(\"klasse\") == \"redner\":\n",
    "                continue\n",
    "            else:\n",
    "                # Actual text content of speech!\n",
    "                # Get text of the paragraph and remove potential irrelevant whitespaces\n",
    "                p_text = element.text.strip() if element.text else \"\"\n",
    "                \n",
    "                item = {\"paragraphs\": p_text}\n",
    "                paragraphs_text.append(item)\n",
    "        \n",
    "        # Other tags like <kommentar> are implicitly skipped as they are not 'p'\n",
    "\n",
    "    return (speech_id, paragraphs_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7eee91013bc3dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:47.557399Z",
     "start_time": "2025-06-04T18:15:47.553802Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_paragraphs_classified_table(reset_db:bool=False):\n",
    "    \"\"\"\n",
    "    Creates a table for classified paragraphs in the database.\n",
    "\n",
    "    Args:\n",
    "        reset_db (bool): If True, drops the table if it exists before creating it.\n",
    "                         Defaults to False.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if reset_db:\n",
    "        con.execute(\"DROP TABLE IF EXISTS group_mention\")\n",
    "        con.execute(\"DROP SEQUENCE IF EXISTS group_mention_id_seq\")\n",
    "\n",
    "    # Create a sequence for the primary key\n",
    "    con.execute(\"CREATE SEQUENCE IF NOT EXISTS group_mention_id_seq START 1;\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS group_mention (\n",
    "            id INTEGER DEFAULT nextval('group_mention_id_seq') PRIMARY KEY,\n",
    "            paragraph_no INTEGER, -- If its 0, its the first paragraph of the speech, 1 for the second, etc.\n",
    "            speech_id VARCHAR NOT NULL REFERENCES speech(id),\n",
    "            paragraph VARCHAR NOT NULL,\n",
    "            group_text VARCHAR NOT NULL, -- This is the group mention, e.g. die Mitglieder der SPD-Fraktion\n",
    "            label VARCHAR(15) NOT NULL,\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07d0a096dc1c114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T06:08:44.699155Z",
     "start_time": "2025-06-05T06:08:43.970221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing::   9%|▊         | 43/500 [01:04<05:52,  1.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected unexpected tag: kommentar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing::  12%|█▏        | 62/500 [01:31<12:13,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected unexpected tag: kommentar\n",
      "Detected unexpected tag: kommentar\n",
      "Detected unexpected tag: kommentar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing::  61%|██████    | 306/500 [06:38<03:21,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected unexpected tag: kommentar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:: 100%|██████████| 500/500 [11:25<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "def smart_join(tokens):\n",
    "    \"\"\"\n",
    "    Joins a list of word tokens into a single string, handling punctuation\n",
    "    and sub-word prefixes ('##') correctly.\n",
    "\n",
    "    Args:\n",
    "        tokens (list[str]): A list of word tokens, which may include sub-word tokens prefixed with '##'.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string with tokens joined together, ensuring proper spacing around punctuation.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Define punctuation that should not have a preceding space\n",
    "    no_space_before = {',', '.', '?', '!', ';', ':', ')'}\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # If it's the very first token, a punctuation mark, or a sub-word,\n",
    "        # don't add a leading space.\n",
    "        if i > 0 and token not in no_space_before and not token.startswith('##'):\n",
    "            result.append(' ')\n",
    "            \n",
    "        # Append the token itself, removing any '##' prefixes\n",
    "        result.append(token.replace('##', ''))\n",
    "        \n",
    "    return \"\".join(result).replace(' - ', '-') # Removes the space before and after a hyphen (Bindestrich)\n",
    "\n",
    "def extract_groups(paragraph:list[tuple[str,str]]) -> list[tuple[str, str]]:\n",
    "    \"\"\" Extracts group mention along with their labels from a paragraph. It groups tokens by their entity labels to get the full mention.\n",
    "    If a mention is broken e.g it does not start with a 'B-' label, it will be filtered.\n",
    "\n",
    "    Args:\n",
    "        paragraph (list[tuple[str,str]]): A list of tuples containing tokens and their corresponding labels.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: A list of tuples where each tuple contains the entity label and a list of (token, label) pairs for that entity, which contain the full mention.\n",
    "    \"\"\"\n",
    "    # This is a set of special tokens that should be ignored in the grouping process. -> adjust it if necessary\n",
    "    SPECIAL = {\"[CLS]\", \"[SEP]\", \"[PAD]\", \"[UNK]\"}\n",
    "    # empty list for groups of paragraph\n",
    "    groups = []\n",
    "    # This is a temporary list to hold the current group mention\n",
    "    group_tmp = []\n",
    "    # This is a flag to indicate if we are currently inside a group mention\n",
    "    group_started = False\n",
    "    entity = \"\" # This hold the current entity. e.g. EOPOL for B-EOPOL\n",
    "    for token, label in paragraph:\n",
    "        # If token is a special token like [CLS] skip it\n",
    "        if token in SPECIAL:\n",
    "            continue\n",
    "        # Check for begin of group\n",
    "        elif label.startswith(\"B-\"):\n",
    "            group_started = True\n",
    "            entity = label[2:]\n",
    "            if group_tmp:\n",
    "                groups.append((entity, group_tmp))\n",
    "                group_tmp = [] # New Group will begin\n",
    "            # Append new beginning label\n",
    "            group_tmp.append((token, label))\n",
    "        # It is checked that 1) we have an inside label and 2) There was a B- label before!\n",
    "        elif label.startswith(\"I-\") and group_started:  \n",
    "            # Then we check if the entity matches\n",
    "            if label[2:] != entity:\n",
    "                # print(f\"Current label: {label[2:]} doesn't match beginning label: {entity}\") @todo handle this as error log\n",
    "                # Break current group because of the miss-label\n",
    "                group_started = False\n",
    "            else:\n",
    "            # If all tests hold, we append the token and its label to the current group\n",
    "                group_tmp.append((token, label))\n",
    "        elif label == 'O':\n",
    "            # An 'O' Tag is always outside. Thus if we scan one, it means that the current group is over\n",
    "            if group_tmp:\n",
    "                groups.append((entity, group_tmp))\n",
    "                group_tmp = [] # New Group will begin\n",
    "            group_started = False\n",
    "        else:\n",
    "            pass\n",
    "            # print(f\"Filtered faulty classification: ({token}, {label})\") @todo handle this as error log\n",
    "    \n",
    "    # Flush last word\n",
    "    if group_tmp:\n",
    "        groups.append((entity, group_tmp))\n",
    "\n",
    "    return groups\n",
    "\n",
    "def insert_paragraph(speech_id:int, index:int, entity:str, group_clean_text:str, paragraph:str):\n",
    "    \"\"\"\n",
    "    Inserts a classified paragraph into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (int): The ID of the speech.\n",
    "        index (int): The index of the paragraph in the speech. 0 for the first paragraph, 1 for the second, etc.\n",
    "        entity (str): The entity label of the paragraph. For example, 'EOPOL' for B-EOPOL.\n",
    "        group_clean_text (str): The cleaned text of the paragraph.\n",
    "        paragraph (str): The original paragraph text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO group_mention (paragraph_no, speech_id, paragraph, group_text, label)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ON CONFLICT DO NOTHING; -- If the paragraph already exists, do nothing\n",
    "    \"\"\", (index, speech_id, paragraph, group_clean_text, entity))\n",
    "    con.commit()\n",
    "\n",
    "def insert_group_mention(speech_id:str, index:int, groups:list[tuple[str,list[tuple[str,str]]]], paragraph:str):\n",
    "    \"\"\"Inserts classified paragraphs into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (str): The ID of the speech.\n",
    "        index (int): The index of the paragraph in the speech. 0 for the first paragraph, 1 for the second, etc.\n",
    "        groups (list[tuple[str,list[tuple[str,str]]]]): A list of tuples containing the entity and a list of the token, label pairs for each group.\n",
    "        paragraph (str): The original paragraph text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for group in groups:\n",
    "        entity, raw_tokens = group\n",
    "        tokens = [item[0] for item in raw_tokens]\n",
    "        group_clean_text = smart_join(tokens)\n",
    "        # print(f\"{entity} -> {group_clean_text}\")\n",
    "        insert_paragraph(speech_id, index, entity, group_clean_text, paragraph)\n",
    "\n",
    "\n",
    "def process_speech(speech_id:str, paragraphs:list[dict[str, list[str]]]):\n",
    "    \"\"\"Processes a speech by classifying its paragraphs (extracting group mention) and inserting them into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (str): The ID of the speech.\n",
    "        paragraphs (list[dict[str, list[str]]]): The list of paragraphs, each represented as a dictionary with a 'paragraphs' key containing the text.\n",
    "    \"\"\"\n",
    "    group_mention = predict_batch(paragraphs)\n",
    "    for index, p in enumerate(group_mention):\n",
    "        # print(p)\n",
    "        groups = extract_groups(p)\n",
    "        insert_group_mention(speech_id, index, groups, paragraphs[index].get('paragraphs'))\n",
    "\n",
    "def extract_speech() -> tuple:\n",
    "    sql = \"\"\"\n",
    "        SELECT * \n",
    "        FROM speech\n",
    "        WHERE position NOT IN ('Präsidentin', 'Vizepräsidentin', 'Vizepräsident', 'Präsident')\n",
    "              AND id NOT IN (SELECT speech_id FROM group_mention) -- check that speech wasn't already processed\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "    return con.execute(sql).fetchone()\n",
    "\n",
    "\n",
    "def main():\n",
    "    create_paragraphs_classified_table(reset_db=True)\n",
    "    for i in tqdm(range(500), desc='Processing:'):\n",
    "        speech = extract_speech()\n",
    "        speech_id, paragraphs = preprocess_speech(speech)\n",
    "        process_speech(speech_id, paragraphs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4409f241-97e1-4ddc-b4cb-0cd3ed36df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph_no</th>\n",
       "      <th>speech_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>group_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4337</td>\n",
       "      <td>0</td>\n",
       "      <td>700243</td>\n",
       "      <td>Herr Präsident! Meine sehr verehrten Damen und...</td>\n",
       "      <td>Herr Präsident</td>\n",
       "      <td>EPPOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4338</td>\n",
       "      <td>2</td>\n",
       "      <td>700243</td>\n",
       "      <td>Wir müssen den Mut aufbringen, in unserem Land...</td>\n",
       "      <td>Europa</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4339</td>\n",
       "      <td>3</td>\n",
       "      <td>700243</td>\n",
       "      <td>Die Lage - das spürt jeder hier im Haus, aber ...</td>\n",
       "      <td>den Irak</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4340</td>\n",
       "      <td>4</td>\n",
       "      <td>700243</td>\n",
       "      <td>Deutschland hat darüber hinaus - das gilt es e...</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4341</td>\n",
       "      <td>4</td>\n",
       "      <td>700243</td>\n",
       "      <td>Deutschland hat darüber hinaus - das gilt es e...</td>\n",
       "      <td>die Arbeitnehmer</td>\n",
       "      <td>PFUNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>4547</td>\n",
       "      <td>212</td>\n",
       "      <td>700243</td>\n",
       "      <td>Ich kann mir vorstellen, dass es in Verbänden ...</td>\n",
       "      <td>Verbände</td>\n",
       "      <td>EOPOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4548</td>\n",
       "      <td>214</td>\n",
       "      <td>700243</td>\n",
       "      <td>Wir Deutsche können stolz sein auf die Kraft u...</td>\n",
       "      <td>Wir Deutsche</td>\n",
       "      <td>PNAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>4549</td>\n",
       "      <td>214</td>\n",
       "      <td>700243</td>\n",
       "      <td>Wir Deutsche können stolz sein auf die Kraft u...</td>\n",
       "      <td>unserer Menschen</td>\n",
       "      <td>PGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>4550</td>\n",
       "      <td>214</td>\n",
       "      <td>700243</td>\n",
       "      <td>Wir Deutsche können stolz sein auf die Kraft u...</td>\n",
       "      <td>unserer</td>\n",
       "      <td>EOPOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>4551</td>\n",
       "      <td>215</td>\n",
       "      <td>700243</td>\n",
       "      <td>Wir haben alles, um eine gute Zukunft für unse...</td>\n",
       "      <td>unsere Kinder</td>\n",
       "      <td>PAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  paragraph_no speech_id  \\\n",
       "0    4337             0    700243   \n",
       "1    4338             2    700243   \n",
       "2    4339             3    700243   \n",
       "3    4340             4    700243   \n",
       "4    4341             4    700243   \n",
       "..    ...           ...       ...   \n",
       "210  4547           212    700243   \n",
       "211  4548           214    700243   \n",
       "212  4549           214    700243   \n",
       "213  4550           214    700243   \n",
       "214  4551           215    700243   \n",
       "\n",
       "                                             paragraph        group_text  \\\n",
       "0    Herr Präsident! Meine sehr verehrten Damen und...    Herr Präsident   \n",
       "1    Wir müssen den Mut aufbringen, in unserem Land...            Europa   \n",
       "2    Die Lage - das spürt jeder hier im Haus, aber ...          den Irak   \n",
       "3    Deutschland hat darüber hinaus - das gilt es e...       Deutschland   \n",
       "4    Deutschland hat darüber hinaus - das gilt es e...  die Arbeitnehmer   \n",
       "..                                                 ...               ...   \n",
       "210  Ich kann mir vorstellen, dass es in Verbänden ...          Verbände   \n",
       "211  Wir Deutsche können stolz sein auf die Kraft u...      Wir Deutsche   \n",
       "212  Wir Deutsche können stolz sein auf die Kraft u...  unserer Menschen   \n",
       "213  Wir Deutsche können stolz sein auf die Kraft u...           unserer   \n",
       "214  Wir haben alles, um eine gute Zukunft für unse...     unsere Kinder   \n",
       "\n",
       "     label  \n",
       "0    EPPOL  \n",
       "1      GPE  \n",
       "2      GPE  \n",
       "3      GPE  \n",
       "4    PFUNK  \n",
       "..     ...  \n",
       "210  EOPOL  \n",
       "211   PNAT  \n",
       "212   PGEN  \n",
       "213  EOPOL  \n",
       "214   PAGE  \n",
       "\n",
       "[215 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"select * from group_mention where speech_id = '700243'\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b9992e-d2dc-49ca-ad95-612cc375aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4604ad1-67d6-4194-b3b9-9bf4b64e383f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
