{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bc4d60-4174-4a55-8886-f9cea1d8a8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:52:02.535474Z",
     "start_time": "2025-06-04T17:52:02.530253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 10:31:55.406122: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-05 10:31:55.419800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749112315.434306  575304 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749112315.438882  575304 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-05 10:31:55.455358: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful!!\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "# Import classifier\n",
    "#from ipynb.fs.full.group_classifier import predict_batch\n",
    "from group_classifier import predict_batch\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "# Disables progress bar of .map function\n",
    "disable_progress_bar()\n",
    "print(\"Import successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9c2acf-64d4-4cf4-a816-c9315fef11f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:52:03.428873Z",
     "start_time": "2025-06-04T17:52:03.417474Z"
    }
   },
   "outputs": [],
   "source": [
    " # Connect to sql database\n",
    "con = duckdb.connect(database='../data/database/german-parliament.duckdb', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a49673-3f68-4987-a75c-4ec16e6ed945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:14:43.294435Z",
     "start_time": "2025-06-04T18:14:43.291083Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_speech(speech:tuple) -> tuple[int, list[str]]:\n",
    "    # We only need the speech it to later identify the origin speech\n",
    "    speech_id = speech[0]\n",
    "    text = speech[5]\n",
    "    # Parse xml from string will throw ParseError if not parseable\n",
    "    root = ET.fromstring(text)\n",
    "    # We only need paragraphs -> this filters unecessary information, such as comments or applause\n",
    "    paragraphs = root.findall('p')\n",
    "    paragraphs_text = []\n",
    "    # Get text of paragraphs\n",
    "    for p in paragraphs:\n",
    "        # Use this to filter out speaker information\n",
    "        if p.attrib.get(\"klasse\") == \"redner\":\n",
    "            continue\n",
    "        else:\n",
    "            p_text = p.text.strip()\n",
    "            item = {\"paragraphs\":p_text}\n",
    "            paragraphs_text.append(item) #get text and remove potential irrelevant whitespaces\n",
    "\n",
    "    return (speech_id, paragraphs_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88d696fdd9d371a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:14:46.573119Z",
     "start_time": "2025-06-04T18:14:46.566778Z"
    }
   },
   "outputs": [],
   "source": [
    "#paragraphs = [{'paragraphs': 'Frau Präsidentin! Meine sehr geehrten Damen und Herren Abgeordnete! Umwelt- und Klimaschutz zahlen sich aus\\xa0– das hat heute Morgen unser Finanzminister Olaf Scholz sehr eindrucksvoll dargelegt. Das ist eine der zentralen Botschaften des Bundeshaushaltes für 2021, den die Bundesregierung diese Woche hier in den Deutschen Bundestag einbringt. Sie zahlen sich aus, weil sie gute, gesunde Lebensbedingungen sicherstellen, sie zahlen sich aus, weil sie Standortvorteile sind und Wettbewerbsfähigkeit von morgen sicherstellen, und sie zahlen sich aus, weil sie die Teilhabe aller Menschen in unserem Land sichern und damit auch den Zusammenhalt stärken.'}, {'paragraphs': 'Der Klimaschutz ist daher\\xa0– und das ist genau richtig\\xa0– auch nicht die alleinige Aufgabe der Umweltministerin. Ich habe immer wieder eingefordert, dass die gesamte Bundesregierung, also alle Ministerien, hier Verantwortung übernehmen. Und dieser Haushaltsentwurf zeigt, dass inzwischen alle Ministerien auf dem Weg sind, Klimaministerien zu werden. Das haben Sie gerade bei der Einbringung des Haushalts des Verkehrsministeriums gehört'}, {'paragraphs': '– ja, natürlich!\\xa0–, welches dank Olaf Scholz verstärkt in Bus, in Bahn, in Elektromobilität investiert. Und das sehen Sie in den Haushaltsentwürfen des Wirtschafts-, des Landwirtschafts-, des Bauministeriums.'}, {'paragraphs': 'Die Bundesregierung wird in 2021 so viel wie nie zuvor in der Geschichte der Bundesrepublik in den Klimaschutz investieren.'}, {'paragraphs': 'Sehen Sie sich allein die Ausgaben für den Energie- und Klimafonds an: Sie werden mit knapp 27\\xa0Milliarden Euro\\xa0– nicht Millionen\\xa0– mehr als verdreifacht. Der vorliegende Haushaltsentwurf ist damit die konsequente Fortsetzung des Weges, den die Bundesregierung mit dem Klimaschutzprogramm\\xa02030 und dem Klimaschutzgesetz eingeschlagen hat. Wir bekennen uns zum Ziel der Klimaneutralität in 2050, und wir unterstützen Wirtschaft und Gesellschaft auf dem Weg dahin. Wir investieren ganz massiv in Forschung und Innovation. Wenn Sie sich allein mein Ministerium ansehen: Über den Energie- und Klimafonds sind Investitionen in die Dekarbonisierung der Industrie vorgesehen. Im Finanzplan bis 2024 stehen dafür rund 1,5\\xa0Milliarden Euro zur Verfügung. Ich glaube, das ist sehr gut investiertes Geld.'}, {'paragraphs': 'Wir unterstützen den Markthochlauf von Grünem Wasserstoff\\xa0– das ist wichtig, weil wir Klimaneutralität in der Stahlproduktion sowie in den Bereichen Chemie und Luftfahrt wollen; das eröffnet starke industriepolitische Perspektiven für Deutschland\\xa0–, und wir setzen im Umwelt- und im Klimaschutz beim Kampf gegen den Artenverlust auf neue Technologien wie Digitalisierung und KI und fördern innovative Pilotprojekte.'}, {'paragraphs': 'Mir ist besonders wichtig, zu betonen: Wir schaffen neue Perspektiven in den vom Strukturwandel besonders betroffenen Regionen. Mit diesem Bundeshaushalt werden erstmals Mittel zur Strukturstärkung in den Kohleregionen eingestellt. Im Rahmen des Strukturstärkungsgesetzes ist das Bundesumweltministerium mit einer Vielzahl von Projekten an der Umsetzung von Fördermaßnahmen beteiligt. Hierzu zählen das Zentrum für Biodiversitätsmonitoring in Leipzig, das Kompetenzzentrum für PtX, das Kompetenzzentrum Elektromagnetische Felder sowie das Kompetenzzentrum Klimaschutz in energieintensiven Industrien, alle in der Lausitz beheimatet.'}, {'paragraphs': 'Diese Einrichtungen liegen alle in Ostdeutschland. Ich weise noch mal ausdrücklich darauf hin, weil wir in dieser Woche 30\\xa0Jahre deutsche Einheit feiern; das wird am Freitag mit einer Debatte hier im Bundestag begleitet. Das Bundesumweltministerium hat in der letzten Woche daran erinnert, dass aus dem ehemaligen Todesstreifen, den die DDR an der Grenze zur Bundesrepublik errichtet hatte, in den vergangenen 30\\xa0Jahren das Grüne Band geworden ist. Es ist inzwischen eine Lebenslinie, die Ost und West verbindet und heute zum Lebensraum von vielen bedrohten Tier- und Pflanzenarten und gleichzeitig ein sehr bemerkenswerter Ort der Erinnerungskultur geworden ist.'}, {'paragraphs': 'Umweltschutz wird auch hier immer wieder als Streitthema wahrgenommen. Das ist gut so; denn wir wollen den Wettstreit um die besten politischen Konzepte und Ideen. Was aber unterschätzt wird, ist, wie verbindend die Wirkung des Umweltschutzes ist. Das Grüne Band ist wirklich ein Symbol dafür. Wir verdanken der Umweltbewegung in der DDR einen wichtigen Anteil an der Friedlichen Revolution und auch das großartige Nationalparkprogramm, das inzwischen zu einer verbindenden Erfolgsgeschichte in ganz Deutschland geworden ist.'}, {'paragraphs': 'Meine Damen und Herren, ein Ende der weltweiten Coronapandemie ist noch nicht in Sicht. Wichtig ist, dass der wirtschaftliche Neustart nach dem Lockdown jetzt genutzt werden muss, um mit dem staatlichen Konjunkturprogramm den Aufbruch in eine klimaneutrale Zukunft zu beschleunigen, um den Weg dahin zu ebnen. Die Fenster, die Türen für diese Veränderungen stehen weit offen, und deswegen ist es jetzt so wichtig, zu handeln und umzusteuern.'}, {'paragraphs': 'Unsere deutsche Ratspräsidentschaft ist die perfekte Gelegenheit dafür, das europäische Band im Klimaschutz enger zu knüpfen. Der European Green Deal ist die richtige Antwort der EU-Kommission auf die Klimakrise genauso wie der Vorschlag für eine Anhebung des EU-Klimaziels auf mindestens 55\\xa0Prozent Minderung der Treibhausgase. Beides liegt im deutschen Interesse und verdient unsere volle Unterstützung. Morgen beim informellen Treffen der EU-Umweltministerinnen und ‑minister werde ich mit daran arbeiten, dass wir bald eine Einigung auf europäischer Ebene bei der neuen Klimapolitik und den Klimazielen hinbekommen.'}, {'paragraphs': 'Meine Damen und Herren, schließen möchte ich mit einem Thema, das wichtig ist und das uns seit Anfang der Woche auch öffentlich stärker beschäftigt. Es geht darum, Verantwortung für die Endlagerung unseres Atommülls zu übernehmen. Drei Generationen haben die Atomkraft in Deutschland genutzt, 30\\u202f000\\xa0Generationen werden sich mit den Hinterlassenschaften beschäftigen müssen.'}, {'paragraphs': 'Gestern hat die Bundesgesellschaft für Endlagerung ihren ersten Zwischenbericht vorgelegt. Das ist ein ganz wichtiger Schritt auf dem Weg hin zu einer sicheren Lagerung der Hinterlassenschaften der Atomenergienutzung. Wir brauchen den sichersten Ort in Deutschland für den Atommüll. Entscheidend ist für mich\\xa0– und ich denke, für alle hier im Haus\\xa0–, dass das Verfahren strikt wissenschaftlich ist und dass die Geologie am Ende über den Standort entscheidet. Politische Überzeugungen dürfen hier keine Rolle spielen. Es geht nicht darum, das hier politisch auszufechten, sondern wir brauchen wirklich den sichersten Ort. Wir haben, glaube ich, über Jahrzehnte schmerzhaft gelernt, dass die Endlagersuche nur gemeinsam, dass sie nur solidarisch gelingen kann. Deswegen will ich die Gelegenheit nutzen, hier im Bundestag daran zu erinnern, dass wir mit allen 16\\xa0Bundesländern, mit allen damals im Parlament vertretenen Parteien über Parteigrenzen hinweg diesen Weg der Suche beschlossen haben. Das ist ein breiter Konsens gewesen, und ich bitte darum, diesen Konsens zu bewahren. Ich erwarte von allen, dass sie zu dieser Verantwortung stehen.'}, {'paragraphs': 'Der Einzelplan\\xa016 stellt sich den aktuellen und den langfristigen Herausforderungen. Ich freue mich sehr auf die Beratungen mit Ihnen und werbe natürlich um Ihre Unterstützung.'}, {'paragraphs': 'Herzlichen Dank.'}, {'paragraphs': 'Das Wort hat der Abgeordnete Karsten Hilse für die AfD-Fraktion.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be7eee91013bc3dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:47.557399Z",
     "start_time": "2025-06-04T18:15:47.553802Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_paragraphs_classified_table(reset_db:bool=False):\n",
    "    \"\"\"\n",
    "    Creates a table for classified paragraphs in the database.\n",
    "\n",
    "    Args:\n",
    "        reset_db (bool): If True, drops the table if it exists before creating it.\n",
    "                         Defaults to False.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if reset_db:\n",
    "        con.execute(\"DROP TABLE IF EXISTS classified_paragraphs\")\n",
    "        con.execute(\"DROP SEQUENCE IF EXISTS classified_paragraphs_id_seq\")\n",
    "\n",
    "    # Create a sequence for the primary key\n",
    "    con.execute(\"CREATE SEQUENCE IF NOT EXISTS classified_paragraphs_id_seq START 1;\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS classified_paragraphs (\n",
    "            id INTEGER DEFAULT nextval('classified_paragraphs_id_seq') PRIMARY KEY,\n",
    "            paragraph_id INTEGER, -- If its 0, its the first paragraph of the speech, 1 for the second, etc.\n",
    "            speech_id VARCHAR NOT NULL REFERENCES speech(id),\n",
    "            paragraph VARCHAR NOT NULL,\n",
    "            group_mention VARCHAR NOT NULL, -- This is the group mention, e.g. die Mitglieder der SPD-Fraktion\n",
    "            label VARCHAR(15) NOT NULL,\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07d0a096dc1c114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T06:08:44.699155Z",
     "start_time": "2025-06-05T06:08:43.970221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:: 100%|██████████| 500/500 [05:09<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def smart_join(tokens):\n",
    "    \"\"\"\n",
    "    Joins a list of word tokens into a single string, handling punctuation\n",
    "    and sub-word prefixes ('##') correctly.\n",
    "\n",
    "    Args:\n",
    "        tokens (list[str]): A list of word tokens, which may include sub-word tokens prefixed with '##'.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string with tokens joined together, ensuring proper spacing around punctuation.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Define punctuation that should not have a preceding space\n",
    "    no_space_before = {',', '.', '?', '!', ';', ':', ')'}\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # If it's the very first token, a punctuation mark, or a sub-word,\n",
    "        # don't add a leading space.\n",
    "        if i > 0 and token not in no_space_before and not token.startswith('##'):\n",
    "            result.append(' ')\n",
    "            \n",
    "        # Append the token itself, removing any '##' prefixes\n",
    "        result.append(token.replace('##', ''))\n",
    "        \n",
    "    return \"\".join(result).replace(' - ', '-') # Removes the space before and after a hyphen (Bindestrich)\n",
    "\n",
    "def extract_groups(paragraph:list[tuple[str,str]]) -> list[tuple[str, str]]:\n",
    "    \"\"\" Extracts group mention along with their labels from a paragraph. It groups tokens by their entity labels to get the full mention.\n",
    "    If a mention is broken e.g it does not start with a 'B-' label, it will be filtered.\n",
    "\n",
    "    Args:\n",
    "        paragraph (list[tuple[str,str]]): A list of tuples containing tokens and their corresponding labels.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: A list of tuples where each tuple contains the entity label and a list of (token, label) pairs for that entity, which contain the full mention.\n",
    "    \"\"\"\n",
    "    # This is a set of special tokens that should be ignored in the grouping process. -> adjust it if necessary\n",
    "    SPECIAL = {\"[CLS]\", \"[SEP]\", \"[PAD]\", \"[UNK]\"}\n",
    "    # empty list for groups of paragraph\n",
    "    groups = []\n",
    "    # This is a temporary list to hold the current group mention\n",
    "    group_tmp = []\n",
    "    # This is a flag to indicate if we are currently inside a group mention\n",
    "    group_started = False\n",
    "    entity = \"\" # This hold the current entity. e.g. EOPOL for B-EOPOL\n",
    "    for token, label in paragraph:\n",
    "        # If token is a special token like [CLS] skip it\n",
    "        if token in SPECIAL:\n",
    "            continue\n",
    "        # Check for begin of group\n",
    "        elif label.startswith(\"B-\"):\n",
    "            group_started = True\n",
    "            entity = label[2:]\n",
    "            if group_tmp:\n",
    "                groups.append((entity, group_tmp))\n",
    "                group_tmp = [] # New Group will begin\n",
    "            # Append new beginning label\n",
    "            group_tmp.append((token, label))\n",
    "        # It is checked that 1) we have an inside label and 2) There was a B- label before!\n",
    "        elif label.startswith(\"I-\") and group_started:  \n",
    "            # Then we check if the entity matches\n",
    "            if label[2:] != entity:\n",
    "                # print(f\"Current label: {label[2:]} doesn't match beginning label: {entity}\") @todo handle this as error log\n",
    "                # Break current group because of the miss-label\n",
    "                group_started = False\n",
    "            else:\n",
    "            # If all tests hold, we append the token and its label to the current group\n",
    "                group_tmp.append((token, label))\n",
    "        elif label == 'O':\n",
    "            # An 'O' Tag is always outside. Thus if we scan one, it means that the current group is over\n",
    "            if group_tmp:\n",
    "                groups.append((entity, group_tmp))\n",
    "                group_tmp = [] # New Group will begin\n",
    "            group_started = False\n",
    "        else:\n",
    "            pass\n",
    "            # print(f\"Filtered faulty classification: ({token}, {label})\") @todo handle this as error log\n",
    "    \n",
    "    # Flush last word\n",
    "    if group_tmp:\n",
    "        groups.append((entity, group_tmp))\n",
    "\n",
    "    return groups\n",
    "\n",
    "def insert_paragraph(speech_id:int, index:int, entity:str, group_clean_text:str, paragraph:str):\n",
    "    \"\"\"\n",
    "    Inserts a classified paragraph into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (int): The ID of the speech.\n",
    "        index (int): The index of the paragraph in the speech. 0 for the first paragraph, 1 for the second, etc.\n",
    "        entity (str): The entity label of the paragraph. For example, 'EOPOL' for B-EOPOL.\n",
    "        group_clean_text (str): The cleaned text of the paragraph.\n",
    "        paragraph (str): The original paragraph text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO classified_paragraphs (paragraph_id, speech_id, paragraph, group_mention, label)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ON CONFLICT DO NOTHING; -- If the paragraph already exists, do nothing\n",
    "    \"\"\", (index, speech_id, paragraph, group_clean_text, entity))\n",
    "    con.commit()\n",
    "\n",
    "def insert_classified_paragraphs(speech_id:str, index:int, groups:list[tuple[str,list[tuple[str,str]]]], paragraph:str):\n",
    "    \"\"\"Inserts classified paragraphs into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (str): The ID of the speech.\n",
    "        index (int): The index of the paragraph in the speech. 0 for the first paragraph, 1 for the second, etc.\n",
    "        groups (list[tuple[str,list[tuple[str,str]]]]): A list of tuples containing the entity and a list of the token, label pairs for each group.\n",
    "        paragraph (str): The original paragraph text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for group in groups:\n",
    "        entity, raw_tokens = group\n",
    "        tokens = [item[0] for item in raw_tokens]\n",
    "        group_clean_text = smart_join(tokens)\n",
    "        # print(f\"{entity} -> {group_clean_text}\")\n",
    "        insert_paragraph(speech_id, index, entity, group_clean_text, paragraph)\n",
    "\n",
    "\n",
    "def process_speech(speech_id:str, paragraphs:list[dict[str, list[str]]]):\n",
    "    \"\"\"Processes a speech by classifying its paragraphs (extracting group mention) and inserting them into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (str): The ID of the speech.\n",
    "        paragraphs (list[dict[str, list[str]]]): The list of paragraphs, each represented as a dictionary with a 'paragraphs' key containing the text.\n",
    "    \"\"\"\n",
    "    classified_paragraphs = predict_batch(paragraphs)\n",
    "    for index, p in enumerate(classified_paragraphs):\n",
    "        # print(p)\n",
    "        groups = extract_groups(p)\n",
    "        insert_classified_paragraphs(speech_id, index, groups, paragraphs[index].get('paragraphs'))\n",
    "\n",
    "def extract_speech() -> tuple:\n",
    "    sql = \"\"\"\n",
    "        SELECT * \n",
    "        FROM speech\n",
    "        WHERE position NOT IN ('Präsidentin', 'Vizepräsidentin', 'Vizepräsident', 'Präsident')\n",
    "              AND id NOT IN (SELECT speech_id FROM classified_paragraphs) -- check that speech wasn't already processed\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "    return con.execute(sql).fetchone()\n",
    "\n",
    "\n",
    "def main():\n",
    "    create_paragraphs_classified_table(reset_db=True)\n",
    "    for i in tqdm(range(500), desc='Processing:'):\n",
    "        speech = extract_speech()\n",
    "        speech_id, paragraphs = preprocess_speech(speech)\n",
    "        process_speech(speech_id, paragraphs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93c1314-2a8c-4411-8753-8ad07a3f9419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:17:14.559250Z",
     "start_time": "2025-06-04T18:17:14.550626Z"
    }
   },
   "outputs": [],
   "source": [
    "con.execute(\"select * from classified_paragraphs where label NOT IN ('EPPOL','EOPOL','GPE','EOWIRT','EOSCI','EOFINANZ','EONGO')\").fetchdf().to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbdc43-51e2-47e8-b875-37eecbddf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classified_paragraphs[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4409f241-97e1-4ddc-b4cb-0cd3ed36df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>speaker_harmonised_id</th>\n",
       "      <th>role</th>\n",
       "      <th>position</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>795914</td>\n",
       "      <td>3731</td>\n",
       "      <td>455296</td>\n",
       "      <td>presidency</td>\n",
       "      <td>Vizepräsident</td>\n",
       "      <td>&lt;sp who=\"Eduard Oswald\" parliamentary_group=\"N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  session_id  speaker_harmonised_id        role       position  \\\n",
       "0  795914        3731                 455296  presidency  Vizepräsident   \n",
       "\n",
       "                                             content  \n",
       "0  <sp who=\"Eduard Oswald\" parliamentary_group=\"N...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"select * from speech where id = '795914'\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9992e-d2dc-49ca-ad95-612cc375aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
