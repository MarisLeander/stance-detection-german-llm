{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc4d60-4174-4a55-8886-f9cea1d8a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import xml.etree.ElementTree as ET\n",
    "# Import classifier\n",
    "from ipynb.fs.full.group_classifier import predict_batch\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c2acf-64d4-4cf4-a816-c9315fef11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to sql database\n",
    "con = duckdb.connect(database='../data/database/german-parliament', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a49673-3f68-4987-a75c-4ec16e6ed945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_speech(speech:tuple) -> tuple[int, list[str]]:\n",
    "    # We only need the speech it to later identify the origin speech\n",
    "    speech_id = test_speech[0]\n",
    "    text = test_speech[5]\n",
    "    # Parse xml from string will throw ParseError if not parseable\n",
    "    root = ET.fromstring(text)\n",
    "    # We only need paragraphs -> this filters unecessary information, such as comments or applause\n",
    "    paragraphs = root.findall('p')\n",
    "    paragraphs_text = {\"paragraphs\":[]}\n",
    "    # Get text of paragraphs\n",
    "    for p in paragraphs:\n",
    "        # Use this to filter out speaker information\n",
    "        if p.attrib.get(\"klasse\") == \"redner\":\n",
    "            continue\n",
    "        else:\n",
    "            paragraphs_text[\"paragraphs\"].append(p.text.strip()) #get text and remove potential irrelevant whitespaces\n",
    "\n",
    "    return (speech_id, paragraphs_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce66a08-6c97-468d-9eb1-d68a85d04401",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speech = con.sql(\"select * from speech order by random() limit 1 \").fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81aa924-95e6-44db-8dd3-7dd29e1a8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_id, paragraphs = preprocess_speech(test_speech)\n",
    "\n",
    "print(speech_id)\n",
    "print(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8e9beaa-ae6f-4046-8e56-c131c2df28ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18733dd9-8863-47f1-a191-e2df01904a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ET.tostring(root.find('name'), encoding='unicode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475610f9-34d6-4d42-9a7c-f4425a2857c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
