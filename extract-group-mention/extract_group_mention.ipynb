{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bc4d60-4174-4a55-8886-f9cea1d8a8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:52:02.535474Z",
     "start_time": "2025-06-04T17:52:02.530253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 16:05:40.739407: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-05 16:05:40.752901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749132340.767794  816694 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749132340.772393  816694 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-05 16:05:40.788872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful!!\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "# Import classifier\n",
    "#from ipynb.fs.full.group_classifier import predict_batch\n",
    "from group_classifier import predict_batch\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "# Disables progress bar of .map function\n",
    "disable_progress_bar()\n",
    "print(\"Import successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9c2acf-64d4-4cf4-a816-c9315fef11f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:52:03.428873Z",
     "start_time": "2025-06-04T17:52:03.417474Z"
    }
   },
   "outputs": [],
   "source": [
    " # Connect to sql database\n",
    "con = duckdb.connect(database='../data/database/german-parliament.duckdb', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a49673-3f68-4987-a75c-4ec16e6ed945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:14:43.294435Z",
     "start_time": "2025-06-04T18:14:43.291083Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_speech(speech: tuple) -> tuple[int, list[dict[str, str]]]:\n",
    "    \"\"\"The filtering for skipping_president_remarks is only necessare for periods >= 19 because of the \"new\" format provided by the bundestag. \n",
    "    For periods <19 the method just extracs all the 'p' tags\n",
    "    \"\"\"\n",
    "    speech_id = speech[0]\n",
    "    text_content = speech[5]\n",
    "\n",
    "    # Parse xml from string will throw ParseError if not parseable\n",
    "    root = ET.fromstring(text_content)\n",
    "    \n",
    "    paragraphs_text = []\n",
    "    # skipping_president_remarks is used to detect interruptions of the President\n",
    "    skipping_president_remarks = False\n",
    "\n",
    "    # Iterate over all direct children of the root <rede> element\n",
    "    for element in root:\n",
    "        # 1. Check if we need to STOP skipping\n",
    "        if skipping_president_remarks:\n",
    "            if element.tag == 'p' and element.attrib.get(\"klasse\") == \"redner\":\n",
    "                # We know that the interruption of the president ended and the speech continues after this tag\n",
    "                skipping_president_remarks = False\n",
    "                continue \n",
    "            elif element.tag == 'p':\n",
    "                # Do nothing -> president is speaking\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Detected unexpected tag: {element.tag}\")\n",
    "\n",
    "        # 2. Check if we need to START skipping (President speaks)\n",
    "        if element.tag == 'name':\n",
    "            # Check if the text content of the name tag indicates a presiding\n",
    "            name_text = \"\".join(element.itertext()).strip() # Gets all text within <name>, including children\n",
    "            # State all titles which will get ignored\n",
    "            president_titles = [\"Präsidentin\", \"Präsident\", \"Vizepräsidentin\", \"Vizepräsident\"]\n",
    "            if name_text and any(title in name_text for title in president_titles):\n",
    "                skipping_president_remarks = True\n",
    "                continue # Move to the next element, don't process this <name> tag as a paragraph\n",
    "\n",
    "        # 3. Process <p> tags\n",
    "        if element.tag == 'p':\n",
    "            # Filter out speaker information paragraphs\n",
    "            if element.attrib.get(\"klasse\") == \"redner\":\n",
    "                continue\n",
    "            else:\n",
    "                # Actual text content of speech!\n",
    "                # Get text of the paragraph and remove potential irrelevant whitespaces\n",
    "                p_text = element.text.strip() if element.text else \"\"\n",
    "                \n",
    "                item = {\"paragraphs\": p_text}\n",
    "                paragraphs_text.append(item)\n",
    "        \n",
    "        # Other tags like <kommentar> are implicitly skipped as they are not 'p'\n",
    "\n",
    "    return (speech_id, paragraphs_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7eee91013bc3dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:47.557399Z",
     "start_time": "2025-06-04T18:15:47.553802Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_paragraphs_classified_table(reset_db:bool=False):\n",
    "    \"\"\"\n",
    "    Creates a table for classified paragraphs in the database.\n",
    "\n",
    "    Args:\n",
    "        reset_db (bool): If True, drops the table if it exists before creating it.\n",
    "                         Defaults to False.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if reset_db:\n",
    "        con.execute(\"DROP TABLE IF EXISTS group_mention\")\n",
    "        con.execute(\"DROP SEQUENCE IF EXISTS group_mention_id_seq\")\n",
    "\n",
    "    # Create a sequence for the primary key\n",
    "    con.execute(\"CREATE SEQUENCE IF NOT EXISTS group_mention_id_seq START 1;\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS group_mention (\n",
    "            id INTEGER DEFAULT nextval('group_mention_id_seq') PRIMARY KEY,\n",
    "            paragraph_no INTEGER, -- If its 0, its the first paragraph of the speech, 1 for the second, etc.\n",
    "            speech_id VARCHAR NOT NULL REFERENCES speech(id),\n",
    "            paragraph VARCHAR NOT NULL,\n",
    "            group_text VARCHAR NOT NULL, -- This is the group mention, e.g. die Mitglieder der SPD-Fraktion\n",
    "            label VARCHAR(15) NOT NULL,\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d0a096dc1c114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T06:08:44.699155Z",
     "start_time": "2025-06-05T06:08:43.970221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing::   9%|▊         | 43/500 [01:04<05:52,  1.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected unexpected tag: kommentar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing::  11%|█▏        | 57/500 [01:20<05:18,  1.39it/s]"
     ]
    }
   ],
   "source": [
    "def smart_join(tokens):\n",
    "    \"\"\"\n",
    "    Joins a list of word tokens into a single string, handling punctuation\n",
    "    and sub-word prefixes ('##') correctly.\n",
    "\n",
    "    Args:\n",
    "        tokens (list[str]): A list of word tokens, which may include sub-word tokens prefixed with '##'.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string with tokens joined together, ensuring proper spacing around punctuation.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Define punctuation that should not have a preceding space\n",
    "    no_space_before = {',', '.', '?', '!', ';', ':', ')'}\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # If it's the very first token, a punctuation mark, or a sub-word,\n",
    "        # don't add a leading space.\n",
    "        if i > 0 and token not in no_space_before and not token.startswith('##'):\n",
    "            result.append(' ')\n",
    "            \n",
    "        # Append the token itself, removing any '##' prefixes\n",
    "        result.append(token.replace('##', ''))\n",
    "        \n",
    "    return \"\".join(result).replace(' - ', '-') # Removes the space before and after a hyphen (Bindestrich)\n",
    "\n",
    "def extract_groups(paragraph:list[tuple[str,str]]) -> list[tuple[str, str]]:\n",
    "    \"\"\" Extracts group mention along with their labels from a paragraph. It groups tokens by their entity labels to get the full mention.\n",
    "    If a mention is broken e.g it does not start with a 'B-' label, it will be filtered.\n",
    "\n",
    "    Args:\n",
    "        paragraph (list[tuple[str,str]]): A list of tuples containing tokens and their corresponding labels.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: A list of tuples where each tuple contains the entity label and a list of (token, label) pairs for that entity, which contain the full mention.\n",
    "    \"\"\"\n",
    "    # This is a set of special tokens that should be ignored in the grouping process. -> adjust it if necessary\n",
    "    SPECIAL = {\"[CLS]\", \"[SEP]\", \"[PAD]\", \"[UNK]\"}\n",
    "    # empty list for groups of paragraph\n",
    "    groups = []\n",
    "    # This is a temporary list to hold the current group mention\n",
    "    group_tmp = []\n",
    "    # This is a flag to indicate if we are currently inside a group mention\n",
    "    group_started = False\n",
    "    entity = \"\" # This hold the current entity. e.g. EOPOL for B-EOPOL\n",
    "    for token, label in paragraph:\n",
    "        # If token is a special token like [CLS] skip it\n",
    "        if token in SPECIAL:\n",
    "            continue\n",
    "        # Check for begin of group\n",
    "        elif label.startswith(\"B-\"):\n",
    "            group_started = True\n",
    "            entity = label[2:]\n",
    "            if group_tmp:\n",
    "                groups.append((entity, group_tmp))\n",
    "                group_tmp = [] # New Group will begin\n",
    "            # Append new beginning label\n",
    "            group_tmp.append((token, label))\n",
    "        # It is checked that 1) we have an inside label and 2) There was a B- label before!\n",
    "        elif label.startswith(\"I-\") and group_started:  \n",
    "            # Then we check if the entity matches\n",
    "            if label[2:] != entity:\n",
    "                # print(f\"Current label: {label[2:]} doesn't match beginning label: {entity}\") @todo handle this as error log\n",
    "                # Break current group because of the miss-label\n",
    "                group_started = False\n",
    "            else:\n",
    "            # If all tests hold, we append the token and its label to the current group\n",
    "                group_tmp.append((token, label))\n",
    "        elif label == 'O':\n",
    "            # An 'O' Tag is always outside. Thus if we scan one, it means that the current group is over\n",
    "            if group_tmp:\n",
    "                groups.append((entity, group_tmp))\n",
    "                group_tmp = [] # New Group will begin\n",
    "            group_started = False\n",
    "        else:\n",
    "            pass\n",
    "            # print(f\"Filtered faulty classification: ({token}, {label})\") @todo handle this as error log\n",
    "    \n",
    "    # Flush last word\n",
    "    if group_tmp:\n",
    "        groups.append((entity, group_tmp))\n",
    "\n",
    "    return groups\n",
    "\n",
    "def insert_paragraph(speech_id:int, index:int, entity:str, group_clean_text:str, paragraph:str):\n",
    "    \"\"\"\n",
    "    Inserts a classified paragraph into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (int): The ID of the speech.\n",
    "        index (int): The index of the paragraph in the speech. 0 for the first paragraph, 1 for the second, etc.\n",
    "        entity (str): The entity label of the paragraph. For example, 'EOPOL' for B-EOPOL.\n",
    "        group_clean_text (str): The cleaned text of the paragraph.\n",
    "        paragraph (str): The original paragraph text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO group_mention (paragraph_no, speech_id, paragraph, group_text, label)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ON CONFLICT DO NOTHING; -- If the paragraph already exists, do nothing\n",
    "    \"\"\", (index, speech_id, paragraph, group_clean_text, entity))\n",
    "    con.commit()\n",
    "\n",
    "def insert_group_mention(speech_id:str, index:int, groups:list[tuple[str,list[tuple[str,str]]]], paragraph:str):\n",
    "    \"\"\"Inserts classified paragraphs into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (str): The ID of the speech.\n",
    "        index (int): The index of the paragraph in the speech. 0 for the first paragraph, 1 for the second, etc.\n",
    "        groups (list[tuple[str,list[tuple[str,str]]]]): A list of tuples containing the entity and a list of the token, label pairs for each group.\n",
    "        paragraph (str): The original paragraph text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for group in groups:\n",
    "        entity, raw_tokens = group\n",
    "        tokens = [item[0] for item in raw_tokens]\n",
    "        group_clean_text = smart_join(tokens)\n",
    "        # print(f\"{entity} -> {group_clean_text}\")\n",
    "        insert_paragraph(speech_id, index, entity, group_clean_text, paragraph)\n",
    "\n",
    "\n",
    "def process_speech(speech_id:str, paragraphs:list[dict[str, list[str]]]):\n",
    "    \"\"\"Processes a speech by classifying its paragraphs (extracting group mention) and inserting them into the database.\n",
    "\n",
    "    Args:\n",
    "        speech_id (str): The ID of the speech.\n",
    "        paragraphs (list[dict[str, list[str]]]): The list of paragraphs, each represented as a dictionary with a 'paragraphs' key containing the text.\n",
    "    \"\"\"\n",
    "    group_mention = predict_batch(paragraphs)\n",
    "    for index, p in enumerate(group_mention):\n",
    "        # print(p)\n",
    "        groups = extract_groups(p)\n",
    "        insert_group_mention(speech_id, index, groups, paragraphs[index].get('paragraphs'))\n",
    "\n",
    "def extract_speech() -> tuple:\n",
    "    sql = \"\"\"\n",
    "        SELECT * \n",
    "        FROM speech\n",
    "        WHERE position NOT IN ('Präsidentin', 'Vizepräsidentin', 'Vizepräsident', 'Präsident')\n",
    "              AND id NOT IN (SELECT speech_id FROM group_mention) -- check that speech wasn't already processed\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "    return con.execute(sql).fetchone()\n",
    "\n",
    "\n",
    "def main():\n",
    "    create_paragraphs_classified_table(reset_db=True)\n",
    "    for i in tqdm(range(500), desc='Processing:'):\n",
    "        speech = extract_speech()\n",
    "        speech_id, paragraphs = preprocess_speech(speech)\n",
    "        process_speech(speech_id, paragraphs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6edbdc43-51e2-47e8-b875-37eecbddf1ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group_mention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgroup_mention\u001b[49m[\u001b[38;5;241m8\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group_mention' is not defined"
     ]
    }
   ],
   "source": [
    "print(group_mention[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4409f241-97e1-4ddc-b4cb-0cd3ed36df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>speaker_harmonised_id</th>\n",
       "      <th>role</th>\n",
       "      <th>position</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>795914</td>\n",
       "      <td>3731</td>\n",
       "      <td>455296</td>\n",
       "      <td>presidency</td>\n",
       "      <td>Vizepräsident</td>\n",
       "      <td>&lt;sp who=\"Eduard Oswald\" parliamentary_group=\"N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  session_id  speaker_harmonised_id        role       position  \\\n",
       "0  795914        3731                 455296  presidency  Vizepräsident   \n",
       "\n",
       "                                             content  \n",
       "0  <sp who=\"Eduard Oswald\" parliamentary_group=\"N...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"select * from speech where id = '795914'\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53b9992e-d2dc-49ca-ad95-612cc375aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4604ad1-67d6-4194-b3b9-9bf4b64e383f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
