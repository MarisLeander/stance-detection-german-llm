{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bc4d60-4174-4a55-8886-f9cea1d8a8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:36:45.167962Z",
     "start_time": "2025-06-04T11:36:40.818967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 13:45:15.715750: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 13:45:15.729030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749037515.743797  394960 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749037515.748361  394960 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 13:45:15.764732: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful\n",
      "Import successful!!\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import xml.etree.ElementTree as ET\n",
    "# Import classifier\n",
    "from ipynb.fs.full.group_classifier import predict_batch\n",
    "print(\"Import successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9c2acf-64d4-4cf4-a816-c9315fef11f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:10:27.275856Z",
     "start_time": "2025-06-04T11:10:27.261983Z"
    }
   },
   "outputs": [],
   "source": [
    " # Connect to sql database\n",
    "con = duckdb.connect(database='../data/database/german-parliament', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a49673-3f68-4987-a75c-4ec16e6ed945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:10:27.422554Z",
     "start_time": "2025-06-04T11:10:27.418881Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_speech(speech:tuple) -> tuple[int, list[str]]:\n",
    "    # We only need the speech it to later identify the origin speech\n",
    "    speech_id = test_speech[0]\n",
    "    text = test_speech[5]\n",
    "    # Parse xml from string will throw ParseError if not parseable\n",
    "    root = ET.fromstring(text)\n",
    "    # We only need paragraphs -> this filters unecessary information, such as comments or applause\n",
    "    paragraphs = root.findall('p')\n",
    "    paragraphs_text = []\n",
    "    # Get text of paragraphs\n",
    "    for p in paragraphs:\n",
    "        # Use this to filter out speaker information\n",
    "        if p.attrib.get(\"klasse\") == \"redner\":\n",
    "            continue\n",
    "        else:\n",
    "            p_text = p.text.strip()\n",
    "            item = {\"paragraphs\":p_text}\n",
    "            paragraphs_text.append(item) #get text and remove potential irrelevant whitespaces\n",
    "\n",
    "    return (speech_id, paragraphs_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ce66a08-6c97-468d-9eb1-d68a85d04401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:45:07.301736Z",
     "start_time": "2025-06-04T09:45:07.255846Z"
    }
   },
   "outputs": [],
   "source": [
    "test_speech = con.sql(\"select * from speech where id like '%ID%' order by random() limit 1 \").fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e81aa924-95e6-44db-8dd3-7dd29e1a8a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:45:10.561133Z",
     "start_time": "2025-06-04T09:45:10.539238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID1913007600\n",
      "[{'paragraphs': 'Herzlichen Dank.\\xa0– Herr Präsident! Liebe Kolleginnen und Kollegen! Der Haushalt des Entwicklungsministeriums ist typischerweise auch zu bezeichnen als der Haushalt der Nachhaltigkeit, der Haushalt für den Weltzukunftsvertrag, für die globalen Nachhaltigkeitsziele.'}, {'paragraphs': 'Damit ein solcher Haushalt ausgestattet werden kann, muss aber auch das Land selbst, muss Deutschland nachhaltig sein. Das bedeutet, auch seine eigenen Finanzen nachhaltig auszugestalten, und zwar im Interesse nachfolgender Generationen. Deswegen ist es großartig, dass wir hier erneut ohne neue Schulden auskommen. Dafür auch herzlichen Dank an den Bundesfinanzminister!'}, {'paragraphs': 'Das sehen nicht alle Fraktionen so. Ich glaube, die Grünen haben jetzt im Zusammenhang mit ihren eigenen Vorstellungen zum Klimaschutz vor, neue Schulden aufzunehmen in der Größenordnung von 20\\xa0Milliarden Euro. Das ist nicht unser Weg, weil das nämlich auch bedeuten würde, dass wir eben nicht mehr die Mittel zur Verfügung hätten, um denjenigen zu helfen, bei denen es am dringendsten notwendig ist. Und diese werden von Bundesminister Müller unterstützt.'}, {'paragraphs': 'Sein Thema\\xa0– und das ist das Thema, das uns seit Jahren umtreibt, und ich meine, wegen dessen Ursächlichkeit hätte diese Debatte auch an den Anfang des heutigen Tages gehört\\xa0– ist die gerechte Gestaltung der Globalisierung. Sein Thema ist, dass wir gemeinsam und in wechselseitiger Verantwortung zur guten Entwicklung auf diesem Planeten beitragen. Wenn wir das geschafft haben, dann haben wir ja die Voraussetzungen geschaffen, dass sich Krisen gar nicht erst entwickeln. Dann haben wir die Voraussetzungen geschaffen, dass das Auswärtige Amt vielleicht weniger an unmittelbarer humanitärer Hilfe leisten muss, dann haben wir die Voraussetzungen geschaffen, dass vielleicht Kriege sich nicht entwickeln. Von der logischen Folge her hätte die Debatte über diesen Haushalt also an den Anfang des heutigen Tages gehört.'}, {'paragraphs': 'Lieber Bundesminister, lieber Gerd, du hast mit ungeheurem Engagement, mit ungeheurer Hartnäckigkeit\\xa0– manche würden vielleicht auch sagen: Sturheit\\xa0– dazu beigetragen, dass dein Etat, dass der Etat des Entwicklungsministeriums diese beachtliche Höhe erreicht hat. Und warum hast du das geschafft? Weil es dir einfach am Herzen liegt, weil es aus deinem Herzen kommt. Und das, glaube ich, ist niemandem verborgen in diesem Land, und ich glaube, das, was du in deinem Herzen hast, das trägst du auch hinaus, trägst du auch in unser Land hinaus und begeisterst viele Menschen, die sich da ehrenamtlich oder hauptamtlich engagieren. Ich glaube, das ist eine ganz wichtige, beachtliche Unterstützung und Ermutigung all derjenigen, die hier etwas leisten.'}, {'paragraphs': 'Ich möchte auf ein Thema, mit dem ich mich in der Berichterstattung persönlich befasst habe, noch kurz eingehen. Wir leisten aus dem Entwicklungshaushalt etwa 1\\xa0Milliarde Euro in den Europäischen Entwicklungsfonds. Der Europäische Entwicklungsfonds wird im Moment gespeist aus Beiträgen der Mitgliedstaaten, die in ihn einzahlen\\xa0– die Osteuropäer proportional etwas weniger als andere Länder. Der Europäische Entwicklungsfonds soll jetzt vielleicht in den Haushalt der Europäischen Union überführt werden. Dagegen ist prinzipiell vielleicht nichts zu sagen, aber Kollege von Holtz hat es schon angesprochen: Ich sehe das dann kritisch, wenn in diesem neuen, größeren außen- und entwicklungspolitischen Instrument der EU dann vielleicht die Entwicklungspolitik unter Druck gerät und nicht mehr dieselbe Aufmerksamkeit bekommt, wie sie sie gegenwärtig genießt. Es ist mir also sehr wichtig, dass wir in den Verhandlungen\\xa0– übrigens auch zum mehrjährigen Finanzrahmen\\xa0– auch darauf ganz genau achten werden. Wenn der mehrjährige Finanzrahmen letzten Endes den Gesamthaushalt unter Druck bringt und der in das neue Finanzierungsinstrument integrierte EEF dann auch unter Druck kommt, dann hätten wir genau das Falsche, dann würde nämlich weniger Entwicklungsleistung aus der Europäischen Union erfolgen, und das darf nicht sein. Dann würde ich das Geld lieber in der Verantwortung des nationalen Haushalts belassen.'}, {'paragraphs': 'Herzlichen Dank.'}, {'paragraphs': 'Vielen Dank.\\xa0– Der letzte Redner zu diesem Einzelplan: der Kollege Stefan Sauer, CDU/CSU-Fraktion.'}]\n"
     ]
    }
   ],
   "source": [
    "speech_id, paragraphs = preprocess_speech(test_speech)\n",
    "\n",
    "print(speech_id)\n",
    "print(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8e9beaa-ae6f-4046-8e56-c131c2df28ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:36:46.965921Z",
     "start_time": "2025-06-04T11:36:45.671018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2601c2eb41184dc887b08681238dac09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 8\n"
     ]
    }
   ],
   "source": [
    "classified_paragraphs = predict_batch(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f07d0a096dc1c114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:38:35.681312Z",
     "start_time": "2025-06-04T11:38:35.678298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paragraph 0\n",
      "\tGroup: EPPOL, Text: Herr Präsident\n",
      "\tGroup: EOPOL, Text: des Entwicklungsministeriums\n",
      "\n",
      "\n",
      "Processing paragraph 1\n",
      "\tGroup: GPE, Text: Deutschland\n",
      "\tGroup: EPPOL, Text: den Bundesfinanzminister\n",
      "\n",
      "\n",
      "Processing paragraph 2\n",
      "\tGroup: EOPOL, Text: alle Fraktionen\n",
      "\tGroup: EOPOL, Text: die Grünen\n",
      "\tGroup: EPPOL, Text: Bundesminister Müller\n",
      "\n",
      "\n",
      "Processing paragraph 3\n",
      "\tGroup: EOPOL, Text: das Auswärtige Amt\n",
      "\n",
      "\n",
      "Processing paragraph 4\n",
      "\tGroup: EPPOL, Text: Lieber Bundesminister\n",
      "\tGroup: EPPOL, Text: lieber Gerd\n",
      "\tGroup: EOPOL, Text: des Entwicklungsministeriums\n",
      "\tGroup: PFUNK, Text: viele Menschen, die sich da ehrenamtlich oder hauptamtlich engagieren\n",
      "\n",
      "\n",
      "Processing paragraph 5\n",
      "Filtered faulty classification: (E, I-EOPOL)\n",
      "\tGroup: EOPOL, Text: den Europäischen Entwicklungsfonds\n",
      "\tGroup: EOPOL, Text: der Mitgliedstaaten\n",
      "\tGroup: PNAT, Text: die Osteuropäer\n",
      "\tGroup: EOPOL, Text: der Europäischen Union\n",
      "\tGroup: EPPOL, Text: Kollege von Holtz\n",
      "\tGroup: EOPOL, Text: der EU\n",
      "\tGroup: EOPOL, Text: der\n",
      "\tGroup: EOPOL, Text: der Europäischen Union\n",
      "\n",
      "\n",
      "Processing paragraph 6\n",
      "\n",
      "\n",
      "Processing paragraph 7\n",
      "\tGroup: EPPOL, Text: der Kollege Stefan Sauer, CDU / CSU - Fraktion\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Maybe adjust this set to tokenizer's special tokens\n",
    "SPECIAL = {\"[CLS]\", \"[SEP]\", \"[PAD]\", \"[UNK]\"}\n",
    "for index, p in enumerate(classified_paragraphs):\n",
    "    print(f\"Processing paragraph {index}\")\n",
    "    groups = []\n",
    "    group_tmp = []\n",
    "    group_started = False\n",
    "    entity = \"\" # This hold the current entity. e.g. EOPOL for B-EOPOL\n",
    "    for token, label in p:\n",
    "        # If token is a special token like [CLS] skip it\n",
    "        if token in SPECIAL:\n",
    "            continue\n",
    "        # Check for begin of group\n",
    "        elif label.startswith(\"B-\"):\n",
    "            group_started = True\n",
    "            entity = label[2:]\n",
    "            if group_tmp:\n",
    "                groups.append(group_tmp)\n",
    "                group_tmp = [] # New Group will begin\n",
    "            # Append new beginning label\n",
    "            group_tmp.append((token, label))\n",
    "        # It is checked that 1) we have an inside label and 2) There was a B- label before!\n",
    "        elif label.startswith(\"I-\") and group_started:  \n",
    "            # Then we check if the entity matches\n",
    "            if label[2:] != entity:\n",
    "                print(f\"Current label: {label[2:]} doesn't match beginning label: {entity}\")\n",
    "                # Break current group because of the miss-label\n",
    "                group_started = False\n",
    "            else:\n",
    "            # If all tests hold, we append the token and its label to the current group\n",
    "                group_tmp.append((token, label))\n",
    "        elif label == 'O':\n",
    "            # An 'O' Tag is always outside. Thus if we scan one, it means that the current group is over\n",
    "            if group_tmp:\n",
    "                groups.append(group_tmp)\n",
    "                group_tmp = [] # New Group will begin\n",
    "            group_started = False\n",
    "        else:\n",
    "            print(f\"Filtered faulty classification: ({token}, {label})\")\n",
    "    \n",
    "    # Flush last word\n",
    "    if group_tmp:\n",
    "        groups.append(group_tmp)\n",
    "    \n",
    "    for group in groups:\n",
    "        _, entity = group[0]\n",
    "        entity = entity[2:] # Get rid of  \"B-\" tag\n",
    "        tokens = [item[0] for item in group]\n",
    "        group_joined = smart_join(tokens)\n",
    "        print(f\"\\tGroup: {entity}, Text: {group_joined}\")\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbb4823b910f53d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: PFUNK, Text: der Arbeitnehmerinnen und Arbeitnehmer\n",
      "Group: PFUNK, Text: der Arbeitnehmerinnen und Arbeitnehmer\n",
      "Group: EOPOL, Text: das Bündnis für Arbeit\n",
      "Group: PFUNK, Text: der in den Betrieben Beschäftigten\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f93c1314-2a8c-4411-8753-8ad07a3f9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_join(tokens):\n",
    "    \"\"\"\n",
    "    Joins a list of word tokens into a single string, handling punctuation\n",
    "    and sub-word prefixes ('##') correctly.\n",
    "\n",
    "    Args: @todo\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Define punctuation that should not have a preceding space\n",
    "    no_space_before = {',', '.', '?', '!', ';', ':', ')'}\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # If it's the very first token, a punctuation mark, or a sub-word,\n",
    "        # don't add a leading space.\n",
    "        if i > 0 and token not in no_space_before and not token.startswith('##'):\n",
    "            result.append(' ')\n",
    "            \n",
    "        # Append the token itself, removing any '##' prefixes\n",
    "        result.append(token.replace('##', ''))\n",
    "        \n",
    "    return \"\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbdc43-51e2-47e8-b875-37eecbddf1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
