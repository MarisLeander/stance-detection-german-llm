{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:48:07.725259Z",
     "start_time": "2025-07-01T09:48:07.721835Z"
    }
   },
   "outputs": [],
   "source": [
    "import duckdb as db\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0655fdee310b638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:53:54.562653Z",
     "start_time": "2025-07-01T09:53:54.557898Z"
    }
   },
   "outputs": [],
   "source": [
    "def connect_to_db(db_path: str) -> db.DuckDBPyConnection:\n",
    "    \"\"\"\n",
    "    Connect to a DuckDB database.\n",
    "\n",
    "    Args:\n",
    "        db_path (str): The path to the DuckDB database file.\n",
    "\n",
    "    Returns:\n",
    "        duckdb.DuckDBPyConnection: A connection object to the DuckDB database.\n",
    "    \"\"\"\n",
    "    return db.connect(database=db_path, read_only=False)\n",
    "\n",
    "def create_data_tables(con:db.DuckDBPyConnection, reset_db:bool=False) -> None:\n",
    "    \"\"\"\n",
    "    Build the table with our annotated paragraphs, aswell as our engineering, test splits.\n",
    "\n",
    "    Args:\n",
    "        con (db.DuckDBPyConnection): The connection to the DuckDB database.\n",
    "        reset_db (bool): Indicates if the whole database will be reset\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if reset_db:\n",
    "        con.execute(\"DROP TABLE IF EXISTS annotations\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS engineering_data\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS test_data\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS annotated_paragraphs\")\n",
    "\n",
    "    sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS annotated_paragraphs (\n",
    "            id INTEGER PRIMARY KEY REFERENCES group_mention(id),\n",
    "            group_text VARCHAR NOT NULL,\n",
    "            inference_paragraph VARCHAR NOT NULL,\n",
    "            adjusted_span BOOLEAN NOT NULL\n",
    "            );\n",
    "    \"\"\"\n",
    "    con.execute(sql)\n",
    "    \n",
    "\n",
    "\n",
    "def create_annotation_table(con:db.DuckDBPyConnection, reset_annotations:bool=False) -> None:\n",
    "    \"\"\"\n",
    "    Creates our tables to insert our annotations from our annotators into.\n",
    "\n",
    "    Args:\n",
    "        con (db.DuckDBPyConnection): The connection to the DuckDB database.\n",
    "        reset_db (bool): Indicates if the annotations will be reset\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if reset_annotations:\n",
    "        con.execute(\"DROP TABLE IF EXISTS annotations\")\n",
    "\n",
    "    sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS annotations (\n",
    "            id INTEGER NOT NULL,\n",
    "            annotator VARCHAR(32) NOT NULL,\n",
    "            annotated_paragraph_id INTEGER NOT NULL REFERENCES annotated_paragraphs(id),\n",
    "            stance VARCHAR(8) CHECK (stance IN ('favour', 'against', 'neither', 'not a group')),\n",
    "            PRIMARY KEY(id, annotator)\n",
    "        );\n",
    "    \"\"\"\n",
    "    con.execute(sql)\n",
    "\n",
    "def create_test_engineering_split(con:db.DuckDBPyConnection) -> None:\n",
    "    \"\"\"\n",
    "    Creates our engineering, test splits.\n",
    "\n",
    "    Args:\n",
    "        con (db.DuckDBPyConnection): The connection to the DuckDB database.\n",
    "        reset_db (bool): Indicates if the database will be reset\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    con.execute(\"CREATE TABLE IF NOT EXISTS engineering_data (id INTEGER PRIMARY KEY REFERENCES annotated_paragraphs(id));\")\n",
    "\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO engineering_data (id)\n",
    "        SELECT id\n",
    "        FROM annotated_paragraphs\n",
    "        USING SAMPLE reservoir(100 ROWS) REPEATABLE (42);\n",
    "        \"\"\"\n",
    "    con.execute(sql)\n",
    "\n",
    "    con.execute(\"CREATE TABLE IF NOT EXISTS test_data (id INTEGER PRIMARY KEY REFERENCES annotated_paragraphs(id));\")\n",
    "\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO test_data (id)\n",
    "        SELECT id\n",
    "        FROM annotated_paragraphs\n",
    "        WHERE id NOT IN (SELECT id from engineering_data);\n",
    "        \"\"\"\n",
    "    con.execute(sql)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8be388a25a49e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:53:54.749556Z",
     "start_time": "2025-07-01T09:53:54.744609Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_inference_para(paragraph:str, group_span_adjustment:list[dict]) -> str:\n",
    "    # remove the span tags\n",
    "    clean_paragraph = paragraph.replace(\"<span>\", \"\").replace(\"</span>\", \"\")\n",
    "    # get placement of adjusted group span\n",
    "\n",
    "    offsets = group_span_adjustment[0].get('globalOffsets')\n",
    "    start = offsets.get(\"start\")\n",
    "    end = offsets.get(\"end\")\n",
    "\n",
    "\n",
    "    # input validation\n",
    "    # ensures start and end are valid integers and in the correct order.\n",
    "    if not (isinstance(start, int) and isinstance(end, int) and 0 <= start <= end <= len(clean_paragraph)):\n",
    "        print(f\"Warning: Invalid offsets provided. start={start}, end={end}, text_length={len(clean_paragraph)}\")\n",
    "        # Return the original text if offsets are invalid to prevent errors.\n",
    "        return None\n",
    "\n",
    "    # slice string, based on offsets to build new inference paragraph\n",
    "    before_span = clean_paragraph[:start]\n",
    "    span_content = clean_paragraph[start:end]\n",
    "    after_span = clean_paragraph[end:]\n",
    "\n",
    "    # construct the new string with the tags wrapped around the middle part.\n",
    "    return f\"{before_span}<span>{span_content}</span>{after_span}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8562d8bb0b6660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:53:54.947351Z",
     "start_time": "2025-07-01T09:53:54.941884Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_primary_annotations(path:str, con:db.DuckDBPyConnection) -> None:\n",
    "    \"\"\" Processes annotations from the primary annotator. This will be used, to\n",
    "        build our annotated_paragraphs table. That means only the inference paragraphs are used / adjusted.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the annotation file.\n",
    "        con (db.DuckDBPyConnection): the database connection\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Read annotated data\n",
    "    annotation_data = pd.read_csv(path)\n",
    "    # Iterate over each annotated entry and add it to db\n",
    "    for index, row in annotation_data.iterrows():\n",
    "        group_text = row['group_text']\n",
    "        paragraph_id = row['id']\n",
    "        inference_paragraph = row['inference_paragraph']\n",
    "        group_span_adjustments = row['answer']\n",
    "        adjusted_span = False\n",
    "\n",
    "        if not pd.isna(group_span_adjustments):\n",
    "            adjusted_span = True\n",
    "            # Convert list string into list\n",
    "            group_span_adjustments = json.loads(group_span_adjustments)\n",
    "            # If our adjustments are not NA it means, that the group span was adjusted!\n",
    "            inference_paragraph = adjust_inference_para(inference_paragraph, group_span_adjustments)\n",
    "            # Adjust group text, since the group span was adjusted\n",
    "            group_text = group_span_adjustments[0].get('text')\n",
    "            \n",
    "        # Insert annotated paragraph into db\n",
    "        sql = \"\"\"\n",
    "            INSERT INTO annotated_paragraphs (id, group_text, inference_paragraph, adjusted_span)\n",
    "                 VALUES (?, ?, ?, ?)\n",
    "              \"\"\"\n",
    "        con.execute(sql, (paragraph_id, group_text, inference_paragraph, adjusted_span))\n",
    "\n",
    "def process_annotations(path:str, annotator:str, con:db.DuckDBPyConnection) -> None:\n",
    "    \"\"\" Processes annotations from an annotator. This will be used, to fill the annotations table, where annotations from each annotator are stored\n",
    "    \n",
    "    Args:\n",
    "        path (str): The path to the annotation file.\n",
    "        annotator (str): The name of the annotator\n",
    "        con (db.DuckDBPyConnection): The database connection\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Read annotated data\n",
    "    annotation_data = pd.read_csv(path)\n",
    "\n",
    "    for index, row in annotation_data.iterrows():\n",
    "        id = index\n",
    "        annotator = annotator.lower()\n",
    "        paragraph_id = row['id']\n",
    "        stance = row['stance_annotation'].lower()\n",
    "        sql = \"INSERT INTO annotations (id, annotator, annotated_paragraph_id, stance) VALUES (?, ?, ?, ?);\"\n",
    "        con.execute(sql, (id, annotator, paragraph_id, stance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9865000ebba20a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T08:07:10.405572Z",
     "start_time": "2025-07-01T08:07:10.312493Z"
    }
   },
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Could not drop the table because this table is main key table of the table \"annotations\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinished processing\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m con.begin()\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# create_data_tables(con, reset_db=args.reset_db)\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# create_annotation_table(con, reset_annotations=args.reset_annotations)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mcreate_data_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_db\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m create_annotation_table(con, reset_annotations=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     35\u001b[39m con.commit()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mcreate_data_tables\u001b[39m\u001b[34m(con, reset_db)\u001b[39m\n\u001b[32m     25\u001b[39m     create_annotation_table(con, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# If the whole db is reset, we need to rebuild the annotations\u001b[39;00m\n\u001b[32m     26\u001b[39m     create_test_engineering_split(con, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# If the whole db is reset, we need to rebuild the engineering / test split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDROP TABLE IF EXISTS annotated_paragraphs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m sql = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m    CREATE TABLE IF NOT EXISTS annotated_paragraphs (\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m        id INTEGER PRIMARY KEY REFERENCES group_mention(id),\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m \u001b[33m        );\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     37\u001b[39m con.execute(sql)\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: Could not drop the table because this table is main key table of the table \"annotations\""
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\" Main function to process annotated data.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Get path to db\n",
    "    home_dir = Path.home()\n",
    "    db_path = home_dir / \"stance-detection-german-llm\" / \"data\" / \"database\" / \"german-parliament.duckdb\"\n",
    "    # Get db connection\n",
    "    con = connect_to_db(db_path)\n",
    "\n",
    "\n",
    "\n",
    "    # build argparser, to pass information whether to reset db or not when starting the script\n",
    "    parser = argparse.ArgumentParser(description=\"Process annotated data.\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--reset_db\",\n",
    "        action='store_true', # This is the key change\n",
    "        help=\"If this flag is present, all tables will be reset.\"\n",
    "    )\n",
    "     parser.add_argument(\n",
    "        \"--reset_annotations\",\n",
    "        action='store_true', # This is the key change\n",
    "        help=\"If this flag is present, the annotations table will be reset.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    con.begin()\n",
    "    if args.reset_db:\n",
    "        create_data_tables(con, reset_db=True)\n",
    "        create_annotation_table(con, reset_annotations=True)\n",
    "    elif args.reset_annotations:\n",
    "        create_annotation_table(con, reset_annotations=True)\n",
    "    con.commit()\n",
    "    \n",
    "    print(\"Start processing of annotations...\")\n",
    "    con.begin()\n",
    "    path =  home_dir / \"stance-detection-german-llm\" / \"data\" / \"annotated_data\"/ \"maris-2025-06-30-14-57-790f3829.csv\"\n",
    "    # ---- Build annotated_paragraphs table ----\n",
    "    process_primary_annotations(path, con)\n",
    "    con.commit()\n",
    "\n",
    "    # --- Build annotations table for each annotator ---\n",
    "    annotator_files = [(\"maris-2025-06-30-14-57-790f3829.csv\", \"maris\"),('harriet_tmp-2025-07-01-13-33-c16b5183.csv', 'harriet_tmp')]\n",
    "\n",
    "    for file, name in annotator_files:\n",
    "        path =  home_dir / \"stance-detection-german-llm\" / \"data\" / \"annotated_data\"/ \"maris-2025-06-30-14-57-790f3829.csv\"\n",
    "        con.begin()\n",
    "        process_annotations(path, name, con)\n",
    "        con.commit()\n",
    "\n",
    "    \n",
    "    if args.reset_db:\n",
    "        con.begin()\n",
    "        create_test_engineering_split(con, True) # If the whole db is reset, we need to rebuild the engineering / test split\n",
    "        con.commit()\n",
    "    \n",
    "    con.close()\n",
    "    print(\"Finished processing\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15ee4e43402bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T08:07:10.471887Z",
     "start_time": "2025-07-01T08:07:10.470365Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b41be97b3d029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
