{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68153d756503ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import duckdb as db\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import locale\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f560967688031d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de_DE.UTF-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the DuckDB database\n",
    "con = db.connect(database='../data/database/plenary_minutes.duckdb', read_only=False)\n",
    "\n",
    "#Set locale for date parsing\n",
    "locale.setlocale(locale.LC_TIME, 'de_DE.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca42ec4e81fba3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(reset_db:bool):\n",
    "    \"\"\"\n",
    "    Create tables in the DuckDB database for storing plenary minutes data.\n",
    "\n",
    "    Args:\n",
    "        reset_db (bool): If True, drop existing tables before creating new ones.\n",
    "    \"\"\"\n",
    "\n",
    "    if reset_db:\n",
    "        con.execute(\"DROP TABLE IF EXISTS plenary_minutes\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS plenary_minutes (\n",
    "            title VARCHAR PRIMARY KEY,\n",
    "            link VARCHAR,\n",
    "            sitting INT,\n",
    "            period INT,\n",
    "            date DATE,\n",
    "            description VARCHAR\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(\"Tables created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad87f5b7b273aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_database(period:int):\n",
    "    \"\"\"\n",
    "    Fills the database with the scraped data from the bundestag website for a given period.\n",
    "\n",
    "    Args:\n",
    "        period (int): The period of the plenary minutes to be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    path = f\"../data/bundestag_open_data_infos/Plenarprotokolle_{period}_wahlperiode.json\"\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        documents = json.load(file)\n",
    "\n",
    "    # Display the data\n",
    "    for doc in documents:\n",
    "        try:\n",
    "            title = doc['title']\n",
    "            link = doc['link']\n",
    "            description = doc['description']\n",
    "            if link == \"No link found\":\n",
    "                continue # Skip if no link is found\n",
    "            elif con.execute(\"SELECT 1 FROM plenary_minutes WHERE link = ?\", (link,)).fetchone():\n",
    "                # File was already downloaded\n",
    "                continue\n",
    "            else:\n",
    "                # Extract sitting number\n",
    "                sitting_match = re.search(r'der (\\d+)\\. Sitzung', title)\n",
    "                sitting_number = sitting_match.group(1) if sitting_match else None\n",
    "\n",
    "                # Extract date\n",
    "                # ðŸ’¡ Fix missing space between month and year (e.g., \"Mai2022\" -> \"Mai 2022\")\n",
    "                # This handles all cases like \"Mai2022\", \"Juni2021\", etc.\n",
    "                title = re.sub(r'([a-zÃ¤Ã¶Ã¼ÃŸA-ZÃ„Ã–Ãœ]+)(\\d{4})', r'\\1 \\2', title)\n",
    "\n",
    "                # Extract date in German format (e.g., \"dem 15. Mai 2022\")\n",
    "                date_match = re.search(r'dem ([\\d\\.]+\\s\\w+\\s\\d{4})', title)\n",
    "                german_date_str = date_match.group(1) if date_match else None\n",
    "                # Convert German date format to datetime object\n",
    "                date_obj = datetime.strptime(german_date_str, \"%d. %B %Y\")\n",
    "\n",
    "                # Convert datetime object to standard format YYYY-MM-DD\n",
    "                date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                # Insert data into the database\n",
    "                sql = f\"\"\"\n",
    "                    INSERT INTO plenary_minutes (title, link, sitting, period, date, description)\n",
    "                    VALUES ('{title}', '{link}', {sitting_number}, {period}, '{date}', '{description}')\n",
    "                \"\"\"\n",
    "                con.execute(sql)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document: {doc}\")\n",
    "            print(f\"Error message: {e}\")\n",
    "\n",
    "def build_database(reset_db:bool=False):\n",
    "    \"\"\"\n",
    "    Build the database with the scraped data from the bundestag website. This is used to save the xml data.\n",
    "\n",
    "    Args:\n",
    "        reset_db (bool): If True, drop existing tables before creating new ones. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create tables\n",
    "    create_tables(reset_db)\n",
    "\n",
    "    # Fill database with data for each period\n",
    "    periods = [19,20,21]\n",
    "    for period in periods:\n",
    "        fill_database(period)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e8cbddb57b232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_xml(link:str) -> str:\n",
    "    \"\"\"\n",
    "    Download the XML file from the given link.\n",
    "\n",
    "    Args:\n",
    "        link (str): The URL of the XML file to download.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the XML file as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(link)\n",
    "    if response.status_code == 200:\n",
    "        xml_content = response.text\n",
    "        if \"Ãƒ\" in xml_content or \"Ã‚\" in xml_content:\n",
    "            xml_content = xml_content.encode(\"latin-1\").decode(\"utf-8\")\n",
    "        # We encode, decode here, to fix faulty decoded xml served by the bundestag api\n",
    "        return xml_content\n",
    "    else:\n",
    "        print(f\"Failed to download {link}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def save_xml_to_file(xml_content:str, folder:str, filename:str):\n",
    "    \"\"\"\n",
    "    Save the XML content to a file.\n",
    "\n",
    "    Args:\n",
    "        xml_content (str): The XML content to save.\n",
    "        folder (str): The folder where the file will be saved.\n",
    "        filename (str): The name of the file to save the XML content to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    with open(os.path.join(folder, filename), 'w') as file:\n",
    "        file.write(xml_content)\n",
    "\n",
    "def get_xml_files():\n",
    "    \"\"\"\n",
    "    Get the list of XML files from the plenary_minutes table in the database.\n",
    "    Then it downloads the XML files from the links and saves them to the specified folder.\n",
    "    \"\"\"\n",
    "    periods = [19, 20, 21]  # Define the periods you want to query\n",
    "    for i in periods:\n",
    "        df = con.execute(f\"SELECT * FROM plenary_minutes WHERE period = {i}\").fetchdf()\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "            link = row['link']\n",
    "            filename = f\"{i}_{row['sitting']:03}_{row['date'].date()}.xml\"\n",
    "            xml_content = download_xml(link)\n",
    "            time.sleep(1)\n",
    "            if xml_content:\n",
    "                save_xml_to_file(xml_content, f\"../data/plenary_minutes/wahlperiode_{i}\", filename)\n",
    "            else:\n",
    "                print(f\"Failed to download {filename} for period {i}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dc51cdcc610d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 239/239 [04:30<00:00,  1.13s/it]\n",
      "Processing rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 214/214 [03:52<00:00,  1.09s/it]\n",
      "Processing rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to build the database and download XML files.\n",
    "    \"\"\"\n",
    "    build_database(reset_db=True)\n",
    "    get_xml_files()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a3bdb-507a-47f8-8b2c-34b300b0aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"select * from plenary_minutes\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b032da86-45c1-40a1-b304-bb63b6aecc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40426385-ff66-4a0c-bf20-8cb09a081b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
